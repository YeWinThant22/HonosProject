{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1146,"status":"ok","timestamp":1719846069416,"user":{"displayName":"Yair win Thant","userId":"10875061210920200624"},"user_tz":-390},"id":"EtgLm-XmTopb"},"outputs":[],"source":["import os"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1719771535124,"user":{"displayName":"Yair win Thant","userId":"10875061210920200624"},"user_tz":-390},"id":"jOhjnNJFVBcu","outputId":"eff32e4e-12f9-4396-baa1-34f1f5c0d13c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34mYOLOv5_Model\u001b[m\u001b[m/            data_training.py         trainingdata_yolo.ipynb\n"]}],"source":["ls"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4755,"status":"ok","timestamp":1719770871802,"user":{"displayName":"Yair win Thant","userId":"10875061210920200624"},"user_tz":-390},"id":"3_X5KdxeVJwJ","outputId":"7c595ca6-3be5-4dfe-f4cf-712d028dfae5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'YOLOV5_Model'...\n","remote: Enumerating objects: 16748, done.\u001b[K\n","remote: Counting objects: 100% (69/69), done.\u001b[K\n","remote: Compressing objects: 100% (54/54), done.\u001b[K\n","remote: Total 16748 (delta 26), reused 46 (delta 15), pack-reused 16679\u001b[K\n","Receiving objects: 100% (16748/16748), 15.36 MiB | 4.96 MiB/s, done.\n","Resolving deltas: 100% (11505/11505), done.\n"]}],"source":["# !git clone https://github.com/ultralytics/yolov5.git YOLOV5_Model\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["'/Users/yewinthant/Desktop/Imp_Honos_Project/YOLO_Waste_Det_And_Cls_Project/Notes/datatraining'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["pwd"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":585,"status":"ok","timestamp":1719846081406,"user":{"displayName":"Yair win Thant","userId":"10875061210920200624"},"user_tz":-390},"id":"CtiOclFTVVn_"},"outputs":[],"source":["os.chdir('yolov5_Model/')"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":551,"status":"ok","timestamp":1719771543700,"user":{"displayName":"Yair win Thant","userId":"10875061210920200624"},"user_tz":-390},"id":"rKDg7E5xXPf7","outputId":"05d1fc19-0fef-489c-fa5c-dc45ce8e865c"},"outputs":[{"name":"stdout","output_type":"stream","text":["CITATION.cff      \u001b[34mclassify\u001b[m\u001b[m/         hubconf.py        tutorial.ipynb\n","CONTRIBUTING.md   \u001b[34mdata\u001b[m\u001b[m/             \u001b[34mmodels\u001b[m\u001b[m/           \u001b[34mutils\u001b[m\u001b[m/\n","LICENSE           data.yaml         pyproject.toml    val.py\n","README.md         \u001b[34mdata_images\u001b[m\u001b[m/      requirements.txt\n","README.zh-CN.md   detect.py         \u001b[34msegment\u001b[m\u001b[m/\n","benchmarks.py     export.py         train.py\n"]}],"source":["ls"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["'/Users/yewinthant/Desktop/Imp_Honos_Project/YOLO_Waste_Det_And_Cls_Project/Notes/datatraining/YOLOv5_Model'"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["pwd"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6258,"status":"ok","timestamp":1719771552308,"user":{"displayName":"Yair win Thant","userId":"10875061210920200624"},"user_tz":-390},"id":"0TLXPbWDXQJI","outputId":"4e3c919a-32a0-4881-8af9-c785e5cab5d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: gitpython>=3.1.30 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (3.1.43)\n","Requirement already satisfied: matplotlib>=3.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (3.9.1)\n","Requirement already satisfied: numpy>=1.23.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.26.4)\n","Requirement already satisfied: opencv-python>=4.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (4.10.0.84)\n","Requirement already satisfied: pillow>=10.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (10.4.0)\n","Requirement already satisfied: psutil in /Users/yewinthant/Library/Python/3.10/lib/python/site-packages (from -r requirements.txt (line 10)) (6.0.0)\n","Requirement already satisfied: PyYAML>=5.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (6.0.1)\n","Requirement already satisfied: requests>=2.32.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (1.14.0)\n","Requirement already satisfied: thop>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n","Requirement already satisfied: torch>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (2.3.1)\n","Requirement already satisfied: torchvision>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (0.18.1)\n","Requirement already satisfied: tqdm>=4.64.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (4.66.4)\n","Requirement already satisfied: ultralytics>=8.2.34 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (8.2.51)\n","Requirement already satisfied: pandas>=1.1.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 27)) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 28)) (0.13.2)\n","Requirement already satisfied: setuptools>=65.5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r requirements.txt (line 42)) (70.3.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.11)\n","Requirement already satisfied: python-dateutil>=2.7 in /Users/yewinthant/Library/Python/3.10/lib/python/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.9.0.post0)\n","Requirement already satisfied: packaging>=20.0 in /Users/yewinthant/Library/Python/3.10/lib/python/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (24.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.2.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.2)\n","Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.53.1)\n","Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.32.0->-r requirements.txt (line 12)) (2024.7.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.32.0->-r requirements.txt (line 12)) (2.2.2)\n","Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.32.0->-r requirements.txt (line 12)) (3.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.32.0->-r requirements.txt (line 12)) (3.3.2)\n","Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.15.4)\n","Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /Users/yewinthant/Library/Python/3.10/lib/python/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.12.2)\n","Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.3)\n","Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2024.6.1)\n","Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.4)\n","Requirement already satisfied: py-cpuinfo in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (9.0.0)\n","Requirement already satisfied: ultralytics-thop>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (2.0.0)\n","Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.1)\n","Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.1)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.1)\n","Requirement already satisfied: six>=1.5 in /Users/yewinthant/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"]}],"source":["!pip3 install -r requirements.txt"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":274034,"status":"ok","timestamp":1719773732146,"user":{"displayName":"Yair win Thant","userId":"10875061210920200624"},"user_tz":-390},"id":"ZXSN6r-NXXY6","outputId":"2079b6d5-9768-428a-fc28-f1c44d39981c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=yolov5s.yaml, data=data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=Model, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v7.0-338-gff063284 Python-3.10.9 torch-2.3.1 CPU\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Overriding model.yaml nc=80 with nc=8\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     35061  models.yolo.Detect                      [8, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","YOLOv5s summary: 214 layers, 7041205 parameters, 7041205 gradients, 16.0 GFLOPs\n","\n","Transferred 342/349 items from yolov5s.pt\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/yewinthant/Desktop/Imp_Honos_Project/YOLO_Waste_Det_And_C\u001b[0m\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/yewinthant/Desktop/Imp_Honos_Project/YOLO_Waste_Det_And_Cls_Project/Notes/datatraining/YOLOv5_Model/data_images/train/labels.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/yewinthant/Desktop/Imp_Honos_Project/YOLO_Waste_Det_And_Cls\u001b[0m\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/yewinthant/Desktop/Imp_Honos_Project/YOLO_Waste_Det_And_Cls_Project/Notes/datatraining/YOLOv5_Model/data_images/test/labels.cache\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.38 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Plotting labels to runs/train/Model6/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/train/Model6\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       0/49         0G    0.06097    0.03625    0.04829          6        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492        0.2      0.326      0.209      0.106\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       1/49         0G    0.04337     0.0317    0.03548         20        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.417      0.428      0.384      0.191\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       2/49         0G    0.04177    0.03132    0.02973          7        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.407      0.412      0.383      0.214\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       3/49         0G    0.04062    0.03175    0.02894         27        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.458      0.421      0.414      0.239\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       4/49         0G     0.0384     0.0318    0.02752         11        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.422      0.381      0.356      0.189\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       5/49         0G    0.03721      0.031    0.02559          9        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492       0.53       0.52      0.536      0.325\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       6/49         0G    0.03588    0.03156    0.02436         16        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.552      0.556      0.559       0.35\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       7/49         0G    0.03499     0.0308    0.02241          8        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.605       0.54      0.585      0.385\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       8/49         0G    0.03449    0.03057    0.02135         13        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.559      0.544      0.562      0.346\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       9/49         0G    0.03367    0.03042    0.02079         13        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.614      0.597      0.614      0.406\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      10/49         0G      0.033    0.02942    0.01965         27        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.588       0.54      0.569      0.369\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      11/49         0G    0.03191     0.0292    0.01981         16        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.607      0.625      0.635      0.407\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      12/49         0G    0.03117    0.02861    0.01825         33        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.674      0.645      0.688      0.474\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      13/49         0G    0.03026    0.02737    0.01688         19        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.669      0.604      0.665      0.457\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      14/49         0G    0.02999    0.02723     0.0175          7        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.664      0.642      0.679       0.47\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      15/49         0G    0.03001    0.02805    0.01649         12        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.706      0.653      0.718      0.496\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      16/49         0G    0.02983     0.0267     0.0161         14        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.732      0.646      0.732      0.494\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      17/49         0G    0.02878     0.0273    0.01476         15        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.723      0.593      0.665      0.454\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      18/49         0G    0.02864    0.02654    0.01459          9        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.679      0.661      0.696       0.49\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      19/49         0G    0.02817    0.02718    0.01398         18        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.699       0.67      0.724      0.514\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      20/49         0G    0.02791    0.02623    0.01399          8        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.721       0.67       0.72      0.507\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      21/49         0G    0.02808    0.02676    0.01277         12        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.744      0.701      0.757      0.543\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      22/49         0G     0.0275    0.02633    0.01194         13        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.749      0.699      0.757      0.535\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      23/49         0G    0.02757    0.02692    0.01233         18        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.739      0.702      0.764      0.556\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      24/49         0G    0.02685    0.02548    0.01292         14        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.754      0.707       0.77      0.555\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      25/49         0G    0.02741    0.02595     0.0117          6        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.784      0.714      0.787      0.578\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      26/49         0G    0.02633    0.02544    0.01133         13        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.772      0.711      0.783      0.574\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      27/49         0G     0.0259    0.02499    0.01153         11        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.762      0.736      0.783      0.576\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      28/49         0G    0.02571    0.02475    0.01075         10        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.782      0.728      0.797       0.59\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      29/49         0G    0.02564    0.02494       0.01         10        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.765      0.722      0.783       0.58\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      30/49         0G    0.02503    0.02469   0.009929         11        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.794      0.721      0.798      0.594\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      31/49         0G    0.02518     0.0244   0.009745         16        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all       1596       3492      0.805      0.721      0.801      0.604\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      32/49         0G    0.02465    0.02389   0.009803         17        640: 1\n","                 Class     Images  Instances          P          R      mAP50   ^C\n","                 Class     Images  Instances          P          R      mAP50   \n","Traceback (most recent call last):\n","  File \"/Users/yewinthant/Desktop/Imp_Honos_Project/YOLO_Waste_Det_And_Cls_Project/Notes/datatraining/YOLOv5_Model/train.py\", line 981, in <module>\n","    main(opt)\n","  File \"/Users/yewinthant/Desktop/Imp_Honos_Project/YOLO_Waste_Det_And_Cls_Project/Notes/datatraining/YOLOv5_Model/train.py\", line 688, in main\n","    train(opt.hyp, opt, device, callbacks)\n","  File \"/Users/yewinthant/Desktop/Imp_Honos_Project/YOLO_Waste_Det_And_Cls_Project/Notes/datatraining/YOLOv5_Model/train.py\", line 457, in train\n","    results, maps, _ = validate.run(\n","  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"/Users/yewinthant/Desktop/Imp_Honos_Project/YOLO_Waste_Det_And_Cls_Project/Notes/datatraining/YOLOv5_Model/val.py\", line 341, in run\n","    preds, train_out = model(im) if compute_loss else (model(im, augment=augment), None)\n","  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/Users/yewinthant/Desktop/Imp_Honos_Project/YOLO_Waste_Det_And_Cls_Project/Notes/datatraining/YOLOv5_Model/models/yolo.py\", line 267, in forward\n","    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n","  File \"/Users/yewinthant/Desktop/Imp_Honos_Project/YOLO_Waste_Det_And_Cls_Project/Notes/datatraining/YOLOv5_Model/models/yolo.py\", line 167, in _forward_once\n","    x = m(x)  # run\n","  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/Users/yewinthant/Desktop/Imp_Honos_Project/YOLO_Waste_Det_And_Cls_Project/Notes/datatraining/YOLOv5_Model/models/common.py\", line 238, in forward\n","    return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), 1))\n","  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/Users/yewinthant/Desktop/Imp_Honos_Project/YOLO_Waste_Det_And_Cls_Project/Notes/datatraining/YOLOv5_Model/models/common.py\", line 86, in forward\n","    return self.act(self.bn(self.conv(x)))\n","  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 460, in forward\n","    return self._conv_forward(input, self.weight, self.bias)\n","  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n","    return F.conv2d(input, weight, bias, self.stride,\n","KeyboardInterrupt\n"]}],"source":["!python3 train.py --data data.yaml --cfg yolov5s.yaml --batch-size 8 --name Model --epochs 50"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":551,"status":"ok","timestamp":1719846571693,"user":{"displayName":"Yair win Thant","userId":"10875061210920200624"},"user_tz":-390},"id":"b9tlL0KYzotx"},"outputs":[],"source":["!python3 export.py --weights runs/train/Model5/weights/best.pt --include torchscript onnx"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1719846221806,"user":{"displayName":"Yair win Thant","userId":"10875061210920200624"},"user_tz":-390},"id":"YGeBQt-k0DOG","outputId":"801a6b70-067c-470e-9372-870e7d0e1a8c"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/Honos_Project/yolov5'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["pwd"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyORDS91ckLRRW7VI7S2ejOX","gpuType":"T4","mount_file_id":"1F_UmsIIHmbDxCfku90st80iU-B_MV2XM","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
